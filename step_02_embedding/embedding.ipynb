{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë¬¸ì„œ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "ì£¼ìš” ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. JSONL íŒŒì¼ì—ì„œ ë¬¸ì„œ ë°ì´í„° ë¡œë“œ\n",
    "2. LangChain Document ê°ì²´ë¡œ ë³€í™˜\n",
    "3. OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ìƒì„±\n",
    "4. ChromaDBì— ë²¡í„° ì €ì¥\n",
    "5. ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "```\n",
    "pip install langchain langchain-openai chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JSONL íŒŒì¼ ë¡œë“œ í•¨ìˆ˜\n",
    "\n",
    "JSONL(JSON Lines) í˜•ì‹ì˜ íŒŒì¼ì—ì„œ ë¬¸ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    JSONL íŒŒì¼ì„ ì½ì–´ì„œ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path: JSONL íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "    Returns:\n",
    "        ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # ë¹ˆ ì¤„ ë¬´ì‹œ\n",
    "                documents.append(json.loads(line))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LangChain Document ê°ì²´ë¡œ ë³€í™˜\n",
    "\n",
    "ì¼ë°˜ ë¬¸ì„œ ë°ì´í„°ë¥¼ LangChainì˜ Document ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_langchain_documents(documents: List[Dict[str, Any]]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        \n",
    "    Returns:\n",
    "        LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    langchain_docs = []\n",
    "    for doc in documents:\n",
    "        langchain_docs.append(\n",
    "            Document(\n",
    "                page_content=doc[\"content\"],\n",
    "                metadata=doc[\"metadata\"]\n",
    "            )\n",
    "        )\n",
    "    return langchain_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OpenAI ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "\n",
    "OpenAIì˜ ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings():\n",
    "    \"\"\"\n",
    "    OpenAI ì„ë² ë”© ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        OpenAI ì„ë² ë”© ëª¨ë¸\n",
    "    \"\"\"\n",
    "    # OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©\n",
    "    # í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "    return OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OpenAI API í‚¤ ì„¤ì •\n",
    "\n",
    "ì•„ë˜ ì…€ì—ì„œ OpenAI API í‚¤ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³´ì•ˆì„ ìœ„í•´ ì‹¤ì œ í‚¤ëŠ” ë…¸íŠ¸ë¶ì— ì €ì¥í•˜ì§€ ë§ˆì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API í‚¤ ì„¤ì • (ì‹¤ì œ í‚¤ëŠ” ë…¸íŠ¸ë¶ì— ì €ì¥í•˜ì§€ ë§ˆì„¸ìš”)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# ë˜ëŠ” .env íŒŒì¼ì—ì„œ ë¡œë“œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë©”ì¸ ì‹¤í–‰ ì½”ë“œ\n",
    "\n",
    "ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL íŒŒì¼ ë¡œë”© ì¤‘: ../step_01_data_set/split_docs.jsonl\n",
      "ì´ 237ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ íŒŒì¼ ê²½ë¡œ\n",
    "input_file = \"../step_01_data_set/split_docs.jsonl\"\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ (ChromaDB ì €ì¥ ìœ„ì¹˜)\n",
    "output_dir = \"../chroma_db\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"JSONL íŒŒì¼ ë¡œë”© ì¤‘: {input_file}\")\n",
    "documents = load_jsonl(input_file)\n",
    "print(f\"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë”©í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í™˜ëœ ë¬¸ì„œ ìˆ˜: 237\n",
      "\n",
      "ì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ:\n",
      "ë‚´ìš©: # Community Projects  \n",
      "Welcome to the Roo Code community section! Here you'll find community projects that extend Roo Code's capabilities and a galler...\n",
      "ë©”íƒ€ë°ì´í„°: {'path': 'community.md', 'name': 'community.md', 'header1': 'Community Projects'}\n"
     ]
    }
   ],
   "source": [
    "# LangChain Document ê°ì²´ë¡œ ë³€í™˜\n",
    "langchain_docs = convert_to_langchain_documents(documents)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¬¸ì„œ ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "# langchain_docs = langchain_docs[:2]\n",
    "\n",
    "print(f\"ë³€í™˜ëœ ë¬¸ì„œ ìˆ˜: {len(langchain_docs)}\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ë¬¸ì„œ ë‚´ìš© í™•ì¸\n",
    "if langchain_docs:\n",
    "    print(\"\\nì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ:\")\n",
    "    print(f\"ë‚´ìš©: {langchain_docs[0].page_content[:150]}...\")\n",
    "    print(f\"ë©”íƒ€ë°ì´í„°: {langchain_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì„ë² ë”© ìƒì„± ë° ChromaDBì— ì €ì¥\n",
    "\n",
    "ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ê³  ChromaDBì— ì €ì¥í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDBì— ë¬¸ì„œ ì¶”ê°€ ì¤‘...\n",
      "ì„ë² ë”© ì™„ë£Œ. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ../chroma_dbì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2082637/3696109469.py:13: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "embeddings = create_embeddings()\n",
    "\n",
    "print(\"ChromaDBì— ë¬¸ì„œ ì¶”ê°€ ì¤‘...\")\n",
    "# ChromaDB ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ë¬¸ì„œ ì¶”ê°€\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=langchain_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=output_dir\n",
    ")\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ì €ì¥\n",
    "vectordb.persist()\n",
    "print(f\"ì„ë² ë”© ì™„ë£Œ. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ìƒì„±ëœ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: 'Roo Codeë€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "\n",
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ê²°ê³¼ 1:\n",
      "ë‚´ìš©: # Roo Code Docs  \n",
      "Roo Code (formerly Roo Cline) is an AI-powered autonomous coding agent that lives in your editor. It helps you code faster and smart...\n",
      "ë©”íƒ€ë°ì´í„°: {'header1': 'Roo Code Docs', 'name': 'index.md', 'path': 'index.md'}\n",
      "\n",
      "ê²°ê³¼ 2:\n",
      "ë‚´ìš©: ## General  \n",
      "### What is Roo Code?  \n",
      "Roo Code is an AI-powered autonomous coding agent that lives in your editor.  \n",
      "### How does Roo Code work?  \n",
      "Roo ...\n",
      "ë©”íƒ€ë°ì´í„°: {'header1': 'Frequently Asked Questions', 'header2': 'General', 'name': 'faq.md', 'path': 'faq.md'}\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "query = \"Roo Codeë€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "print(f\"\\ní…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'\")\n",
    "results = vectordb.similarity_search(query, k=2)\n",
    "\n",
    "print(\"\\nê²€ìƒ‰ ê²°ê³¼:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nê²°ê³¼ {i+1}:\")\n",
    "    print(f\"ë‚´ìš©: {doc.page_content[:150]}...\")\n",
    "    print(f\"ë©”íƒ€ë°ì´í„°: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì¶”ê°€ ì‹¤í—˜: ë‹¤ì–‘í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ë²¡í„° ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ì¿¼ë¦¬: 'Roo Codeì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ê²°ê³¼ 1:\n",
      "ë‚´ìš©: ## What Can Roo Code Do?  \n",
      "- ğŸš€ **Generate Code** from natural language descriptions\n",
      "- ğŸ”§ **Refactor & Debug** existing code\n",
      "- ğŸ“ **Write & Update** docu...\n",
      "ë©”íƒ€ë°ì´í„°: {'header1': 'Roo Code Docs', 'header2': 'What Can Roo Code Do?', 'name': 'index.md', 'path': 'index.md'}\n",
      "\n",
      "\n",
      "ì¿¼ë¦¬: 'Roo Codeë¥¼ ì–´ë–»ê²Œ ì„¤ì¹˜í•˜ë‚˜ìš”?'\n",
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ê²°ê³¼ 1:\n",
      "ë‚´ìš©: # Installing Roo Code  \n",
      "Roo Code is a VS Code extension that brings AI-powered coding assistance to your editor.  There are three main ways to install...\n",
      "ë©”íƒ€ë°ì´í„°: {'header1': 'Installing Roo Code', 'name': 'installing.md', 'path': 'getting-started/installing.md'}\n",
      "\n",
      "\n",
      "ì¿¼ë¦¬: 'Roo Codeì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
      "ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ê²°ê³¼ 1:\n",
      "ë‚´ìš©: ## What Can Roo Code Do?  \n",
      "- ğŸš€ **Generate Code** from natural language descriptions\n",
      "- ğŸ”§ **Refactor & Debug** existing code\n",
      "- ğŸ“ **Write & Update** docu...\n",
      "ë©”íƒ€ë°ì´í„°: {'header1': 'Roo Code Docs', 'header2': 'What Can Roo Code Do?', 'name': 'index.md', 'path': 'index.md'}\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸\n",
    "test_queries = [\n",
    "    \"Roo Codeì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"Roo Codeë¥¼ ì–´ë–»ê²Œ ì„¤ì¹˜í•˜ë‚˜ìš”?\",\n",
    "    \"Roo Codeì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n\\nì¿¼ë¦¬: '{query}'\")\n",
    "    results = vectordb.similarity_search(query, k=1)\n",
    "    \n",
    "    print(\"ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\nê²°ê³¼ {i+1}:\")\n",
    "        print(f\"ë‚´ìš©: {doc.page_content[:150]}...\")\n",
    "        print(f\"ë©”íƒ€ë°ì´í„°: {doc.metadata}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
